-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | A GPU accelerated deep learning library.
--   
@package deep-banana
@version 0.1.0.0


-- | FFI wrapper to custom CUDA code needed for for HNN.
module DeepBanana.Cubits
thresh :: DevicePtr CFloat -> CSize -> CFloat -> DevicePtr CFloat -> IO ()
threshDouble :: DevicePtr CDouble -> CSize -> CDouble -> DevicePtr CDouble -> IO ()
mul :: DevicePtr CFloat -> DevicePtr CFloat -> CSize -> IO ()
mulDouble :: DevicePtr CDouble -> DevicePtr CDouble -> CSize -> IO ()
add :: DevicePtr CFloat -> DevicePtr CFloat -> CSize -> IO ()
addDouble :: DevicePtr CDouble -> DevicePtr CDouble -> CSize -> IO ()
tabs :: DevicePtr CFloat -> CSize -> IO ()
tabsDouble :: DevicePtr CDouble -> CSize -> IO ()
tsignum :: DevicePtr CFloat -> CSize -> IO ()
tsignumDouble :: DevicePtr CDouble -> CSize -> IO ()
subtract :: DevicePtr CFloat -> DevicePtr CFloat -> CSize -> IO ()
subtractDouble :: DevicePtr CDouble -> DevicePtr CDouble -> CSize -> IO ()
tnegate :: DevicePtr CFloat -> CSize -> IO ()
tnegateDouble :: DevicePtr CDouble -> CSize -> IO ()
scale :: CFloat -> DevicePtr CFloat -> CSize -> IO ()
scaleDouble :: CDouble -> DevicePtr CDouble -> CSize -> IO ()
logFloat :: DevicePtr CFloat -> CSize -> IO ()
logDouble :: DevicePtr CDouble -> CSize -> IO ()
inv :: DevicePtr CFloat -> CSize -> IO ()
invDouble :: DevicePtr CDouble -> CSize -> IO ()
texp :: DevicePtr CFloat -> CSize -> IO ()
texpDouble :: DevicePtr CDouble -> CSize -> IO ()
tsqrt :: DevicePtr CFloat -> CSize -> IO ()
tsqrtDouble :: DevicePtr CDouble -> CSize -> IO ()
tsin :: DevicePtr CFloat -> CSize -> IO ()
tsinDouble :: DevicePtr CDouble -> CSize -> IO ()
tcos :: DevicePtr CFloat -> CSize -> IO ()
tcosDouble :: DevicePtr CDouble -> CSize -> IO ()
ttan :: DevicePtr CFloat -> CSize -> IO ()
ttanDouble :: DevicePtr CDouble -> CSize -> IO ()
tasin :: DevicePtr CFloat -> CSize -> IO ()
tasinDouble :: DevicePtr CDouble -> CSize -> IO ()
tacos :: DevicePtr CFloat -> CSize -> IO ()
tacosDouble :: DevicePtr CDouble -> CSize -> IO ()
tatan :: DevicePtr CFloat -> CSize -> IO ()
tatanDouble :: DevicePtr CDouble -> CSize -> IO ()
tsinh :: DevicePtr CFloat -> CSize -> IO ()
tsinhDouble :: DevicePtr CDouble -> CSize -> IO ()
tcosh :: DevicePtr CFloat -> CSize -> IO ()
tcoshDouble :: DevicePtr CDouble -> CSize -> IO ()
ttanh :: DevicePtr CFloat -> CSize -> IO ()
ttanhDouble :: DevicePtr CDouble -> CSize -> IO ()
tasinh :: DevicePtr CFloat -> CSize -> IO ()
tasinhDouble :: DevicePtr CDouble -> CSize -> IO ()
tacosh :: DevicePtr CFloat -> CSize -> IO ()
tacoshDouble :: DevicePtr CDouble -> CSize -> IO ()
tatanh :: DevicePtr CFloat -> CSize -> IO ()
tatanhDouble :: DevicePtr CDouble -> CSize -> IO ()
tpow :: DevicePtr CFloat -> DevicePtr CFloat -> CSize -> IO ()
tpowDouble :: DevicePtr CDouble -> DevicePtr CDouble -> CSize -> IO ()
tmax :: DevicePtr CFloat -> DevicePtr CFloat -> CSize -> IO ()
tmaxDouble :: DevicePtr CDouble -> DevicePtr CDouble -> CSize -> IO ()


-- | Defines datatype which can be used as scalar elements for a tensor.
--   Also exports much needed, although orphan instances for <a>CFloat</a>
--   and <a>CDouble</a>: <a>Generic</a>, <a>NFData</a> and
--   <a>Serialize</a>.
module DeepBanana.Tensor.TensorScalar

-- | Type class for tensor scalars. Basically requires them to be storable,
--   serializable, deepseqable numbers that can be handled by CUDA, Cublas,
--   CuDNN and Haskell. Basically requires low-level numeric routines.
class (Cublas a, Floating a, Storable a, VectorSpace a, a ~ Scalar a, Serialize a, NFData a) => TensorScalar a
datatype :: TensorScalar a => Proxy a -> DataType
thresh :: TensorScalar a => DevicePtr a -> CSize -> a -> DevicePtr a -> IO ()
rawMul :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
rawAdd :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
rawAbs :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSignum :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSubtract :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
rawNegate :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawScale :: TensorScalar a => a -> DevicePtr a -> CSize -> IO ()
rawLog :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawInv :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawExp :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSqrt :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSin :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawCos :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawTan :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAsin :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAcos :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAtan :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSinh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawCosh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawTanh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAsinh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAcosh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAtanh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawPow :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
rawMax :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
generateUniform :: TensorScalar a => Generator -> DevicePtr a -> CSize -> IO Status
generateNormal :: TensorScalar a => Generator -> DevicePtr a -> CSize -> a -> a -> IO Status
generateLogNormal :: TensorScalar a => Generator -> DevicePtr a -> CSize -> a -> a -> IO Status

-- | Haskell type representing the C <tt>float</tt> type.
data CFloat :: *

-- | Haskell type representing the C <tt>double</tt> type.
data CDouble :: *
instance TensorScalar CDouble
instance TensorScalar CFloat
instance NFData CDouble
instance NFData CFloat
instance Serialize CDouble
instance Serialize CFloat
instance Generic CDouble
instance Generic CFloat


-- | Shape type class and instances. Defines the shape of a tensor, both at
--   the type level and value level.
module DeepBanana.Tensor.Shape

-- | Type class for tensor shapes.
class Shape (s :: [Nat]) where type family Size s :: Nat type family Nbdim s :: Nat nbdim p = length $ shape p size p = case shape p of { [] -> 0 xs -> product xs }
shape :: Shape s => Proxy s -> [Int]
nbdim :: Shape s => Proxy s -> Int
size :: Shape s => Proxy s -> Int

-- | Type level function to compute the quotient of the division of
--   <tt>m</tt> by <tt>n</tt>.
--   
--   <pre>
--   natVal (Proxy :: Proxy (Quotient m n)) == natVal (Proxy :: Proxy m) `div` natVal (Proxy :: Proxy n)
--   </pre>

-- | Type level function to compute the remainder of the division of
--   <tt>m</tt> by <tt>n</tt>.
--   
--   <pre>
--   natVal (Proxy :: Proxy (Remainder m n)) == natVal (Proxy :: Proxy m) `rem` natVal (Proxy :: Proxy n)
--   </pre>

-- | Type level max function.
--   
--   <pre>
--   natVal (Proxy :: Proxy (Max m n)) == max (natVal (Proxy :: Proxy m)) (natVal (Proxy :: Proxy n))
--   </pre>
instance (KnownNat e1, Shape (e2 : l)) => Shape (e1 : e2 : l)
instance KnownNat n => Shape '[n]
instance Shape '[]


-- | Mutable GPU multi-dimensional dense numeric arrays, parametrized by
--   the state token of some primitive state monad.
module DeepBanana.Tensor.Mutable

-- | Mutable tensor, parametrized by some state token <tt>st</tt>.
data MTensor st (shp :: [Nat]) a
MTensor :: (ForeignPtr a) -> MTensor st a

-- | Type class for tensor shapes.
class Shape (s :: [Nat]) where type family Size s :: Nat type family Nbdim s :: Nat nbdim p = length $ shape p size p = case shape p of { [] -> 0 xs -> product xs }
shape :: Shape s => Proxy s -> [Int]
nbdim :: Shape s => Proxy s -> Int
size :: Shape s => Proxy s -> Int

-- | Convenient synonym for mutable tensors in the <a>IO</a> monad.
type IOTensor = MTensor RealWorld

-- | Type class for tensor scalars. Basically requires them to be storable,
--   serializable, deepseqable numbers that can be handled by CUDA, Cublas,
--   CuDNN and Haskell. Basically requires low-level numeric routines.
class (Cublas a, Floating a, Storable a, VectorSpace a, a ~ Scalar a, Serialize a, NFData a) => TensorScalar a
datatype :: TensorScalar a => Proxy a -> DataType
thresh :: TensorScalar a => DevicePtr a -> CSize -> a -> DevicePtr a -> IO ()
rawMul :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
rawAdd :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
rawAbs :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSignum :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSubtract :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
rawNegate :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawScale :: TensorScalar a => a -> DevicePtr a -> CSize -> IO ()
rawLog :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawInv :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawExp :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSqrt :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSin :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawCos :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawTan :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAsin :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAcos :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAtan :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawSinh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawCosh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawTanh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAsinh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAcosh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawAtanh :: TensorScalar a => DevicePtr a -> CSize -> IO ()
rawPow :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
rawMax :: TensorScalar a => DevicePtr a -> DevicePtr a -> CSize -> IO ()
generateUniform :: TensorScalar a => Generator -> DevicePtr a -> CSize -> IO Status
generateNormal :: TensorScalar a => Generator -> DevicePtr a -> CSize -> a -> a -> IO Status
generateLogNormal :: TensorScalar a => Generator -> DevicePtr a -> CSize -> a -> a -> IO Status

-- | Returns the CuDNN datatype identifier for the tensor.
dtype :: (PrimMonad m, TensorScalar a) => MTensor (PrimState m) s a -> m DataType

-- | Utility function to insert shape information at the type level. Useful
--   to desambiguate shape for the compiler when putting an explicit type
--   signature, which happens often in monadic code with mutable tensors.
shaped :: Proxy s -> m (MTensor st s a) -> m (MTensor st s a)

-- | Creates an uninitialized mutable tensor with a given shape.
--   Uninitialized means the contents of the tensor are defined by whatever
--   was lying around in memory at the time.
emptyTensor :: (TensorScalar a, Shape s, PrimMonad m) => m (MTensor (PrimState m) s a)

-- | Creates a mutable tensor from a list. Throws an exception at runtime
--   when the size of the list does not correspond to the desired shape.
fromList :: (PrimMonad m, TensorScalar a, Shape s) => [a] -> m (MTensor (PrimState m) s a)

-- | Creates a mutable tensor filled with zeros.
zeros :: (PrimMonad m, Shape s, TensorScalar a) => m (MTensor (PrimState m) s a)

-- | Creates a mutable tensor filled with ones.
ones :: (PrimMonad m, Shape s, TensorScalar a) => m (MTensor (PrimState m) s a)

-- | Runs an <a>IO</a> action with the internal device pointer of a given
--   mutable tensor.
withDevicePtr :: Storable a => IOTensor s a -> (DevicePtr a -> IO b) -> IO b

-- | Type-safe tensor reshaping.
reshape :: (Shape s1, Shape s2, Size s1 ~ Size s2) => MTensor st s1 a -> MTensor st s2 a

-- | Copies the data of a mutable tensor into a new one.
copy :: (PrimMonad m, Shape s, TensorScalar a) => MTensor (PrimState m) s a -> m (MTensor (PrimState m) s a)

-- | Converts a mutable tensor to a list of elements.
toList :: (PrimMonad m, Shape s, TensorScalar a) => MTensor (PrimState m) s a -> m [a]

-- | Thresholds a mutable tensor in place. Used to implement dropout.
threshInplace :: (PrimMonad m, Shape s) => MTensor (PrimState m) s CFloat -> CFloat -> m ()

-- | In place logarithm.
tlog :: (PrimMonad m, Shape s, TensorScalar a) => MTensor (PrimState m) s a -> m ()

-- | In place exponential.
texp :: (PrimMonad m, Shape s, TensorScalar a) => MTensor (PrimState m) s a -> m ()

-- | In place inverse.
inv :: (PrimMonad m, Shape s, TensorScalar a) => MTensor (PrimState m) s a -> m ()

module DeepBanana.Layer.CUDA.Monad
type CUDA = ReaderT CUDAReader IO
data CUDAReader
CUDAReader :: Handle -> Handle -> Generator -> CUDAReader
cublasHandle :: CUDAReader -> Handle
cudnnHandle :: CUDAReader -> Handle
generator :: CUDAReader -> Generator
runCUDA :: CULLong -> CUDA a -> IO a

module DeepBanana.Optimize
sgd :: (Monad m, MonadTrans t, Monad (t (Pipe a (Scalar w, w) m)), Monad (t m), MFunctor t, VectorSpace w) => (Scalar w -> w -> w -> t m w) -> (w -> a -> m (Scalar w, w)) -> w -> t (Pipe a (Scalar w, w) m) ()
type VanillaT s = ReaderT (VanillaReader s)
vanilla :: (VectorSpace w, Monad m) => Scalar w -> w -> w -> VanillaT (Scalar w) m w
runVanilla :: s -> ReaderT (VanillaReader s) m a -> m a
type MomentumT w s = RWST (MomentumReader s) () (MomentumState w)
momentum :: (VectorSpace w, Monad m) => Scalar w -> w -> w -> MomentumT w (Scalar w) m w
runMomentum :: (VectorSpace w, Monad m) => Scalar w -> Scalar w -> MomentumT w (Scalar w) m a -> m a

module DeepBanana.Layer
newtype Layer m a (w :: [*]) inp out
Layer :: (HLSpace a w -> inp -> m (out, out -> (HLSpace a w, inp))) -> Layer m a inp out
forwardBackward :: Layer m a inp out -> HLSpace a w -> inp -> m (out, out -> (HLSpace a w, inp))
newtype HLSpace (a :: *) l
HLS :: HList l -> HLSpace l
unHLS :: HLSpace l -> HList l
forward :: Monad m => Layer m a w inp out -> HLSpace a w -> inp -> m out
backward :: Monad m => Layer m a w inp out -> HLSpace a w -> inp -> out -> m (HLSpace a w, inp)
combinePasses :: Monad m => (HLSpace a w -> inp -> m out) -> (HLSpace a w -> inp -> out -> m (out -> (HLSpace a w, inp))) -> Layer m a w inp out
combinePasses' :: Monad m => (inp -> m out) -> (inp -> out -> m (out -> inp)) -> Layer m a [] inp out
(***) :: (Monad m, AdditiveGroup (HLSpace s w)) => Layer m s w a b -> Layer m s w a' b' -> Layer m s w (a, a') (b, b')
(&&&) :: (Monad m, AdditiveGroup (HLSpace s w), AdditiveGroup a) => Layer m s w a b -> Layer m s w a b' -> Layer m s w a (b, b')
terminal :: (VectorSpace inp, Monad m) => out -> Layer m a [] inp out
(>+>) :: (Monad m, HAppendList w1 w2, HSplitAt n (HAppendListR w1 w2) w1 w2) => Layer m s w1 a b -> Layer m s w2 b c -> Layer m s (HAppendListR w1 w2) a c
(-<) :: (Monad m, VectorSpace i1, VectorSpace i2) => Layer m a w (i1, i2) out -> i1 -> Layer m a w i2 out
space :: Proxy a -> HList l -> HLSpace a l
noWeights :: Monad m => (inp -> m (out, out -> inp)) -> Layer m a [] inp out
effect :: Monad m => (a -> m b) -> Layer m s [] a a
instance (Floating e, Floating (HLSpace a l)) => Floating (HLSpace a (e : l))
instance Floating (HLSpace a '[])
instance (Fractional e, Fractional (HLSpace a l)) => Fractional (HLSpace a (e : l))
instance Fractional (HLSpace a '[])
instance (Num e, Num (HLSpace a l)) => Num (HLSpace a (e : l))
instance Num (HLSpace a '[])
instance (NFData e, NFData (HLSpace a l)) => NFData (HLSpace a (e : l))
instance NFData (HLSpace a '[])
instance (Serialize e, Serialize (HLSpace a l)) => Serialize (HLSpace a (e : l))
instance Serialize (HLSpace a '[])
instance (VectorSpace e, VectorSpace (HLSpace a l), a ~ Scalar e, a ~ Scalar (HLSpace a l)) => VectorSpace (HLSpace a (e : l))
instance VectorSpace (HLSpace a '[])
instance (AdditiveGroup e, AdditiveGroup (HLSpace a l)) => AdditiveGroup (HLSpace a (e : l))
instance AdditiveGroup (HLSpace a '[])
instance Show (HList l) => Show (HLSpace a l)
instance (AdditiveGroup (HLSpace a w), Monad m) => Category (Layer m a w)


-- | GPU multi-dimensional dense numeric arrays.
module DeepBanana.Tensor

-- | An immutable, GPU tensor with a given shape <tt>s</tt>, whose scalar
--   type <tt>a</tt> should be an instance of <a>TensorScalar</a>. Such
--   tensors are instances of <a>Num</a>, <a>Fractional</a> and
--   <a>Floating</a>, implementing all the numeric operations in an
--   elementwise fashion:
--   
--   <pre>
--   &gt;&gt;&gt; fromList [1,2,3] + fromList [3,4,5] :: Tensor '[3] CFloat
--   Tensor [3] [4.0,6.0,8.0]
--   </pre>
--   
--   Scalars are automatically broadcast to whatever shape is necessary:
--   
--   <pre>
--   &gt;&gt;&gt; 5 * fromList [1,2,3] :: Tensor '[3] CFloat
--   Tensor [3] [5.0,10.0,15.0]
--   </pre>
data Tensor (s :: [Nat]) a
Tensor :: (ForeignPtr a) -> Tensor a

-- | Returns the CuDNN datatype of a tensor.
dtype :: TensorScalar a => Tensor s a -> DataType

-- | Type safe reshaping.
reshape :: (Shape s1, Shape s2, Size s1 ~ Size s2) => Tensor s1 a -> Tensor s2 a

-- | Converts a mutable tensor into an immutable one in O(1) time. The data
--   is not copied, so one should make sure the input mutable tensor is not
--   modified after the the conversion. Unsafe.
unsafeFreeze :: PrimMonad m => MTensor (PrimState m) s a -> m (Tensor s a)

-- | Converts an immutable tensor into a mutable one in O(1) time. The data
--   is not copied, so one should make sure the input immutable tensor is
--   not used after the conversion. Unsafe.
unsafeThaw :: PrimMonad m => Tensor s a -> m (MTensor (PrimState m) s a)

-- | Initializes a tensor from list data. If the length of the list does
--   not correspond to the size of the desired shape, throws an exception
--   at run time.
fromList :: (TensorScalar a, Shape s) => [a] -> Tensor s a

-- | Converts a tensor to a list.
toList :: (TensorScalar a, Shape s) => Tensor s a -> [a]

-- | Converts a storable vector to an immutable tensor. Throws an error at
--   runtime when the input's length does not correspond to the desired
--   output size. Runs in O(n) time.
fromVector :: (TensorScalar a, Shape s) => Vector a -> Tensor s a

-- | Converts a tensor to a storable vector. Runs in O(n) time.
toVector :: (TensorScalar a, Shape s) => Tensor s a -> Vector a

-- | Concatenates two 1-dimensional tensors. Inverse of tsplit. Runs in
--   O(n+m) time.
tconcat :: (KnownNat n, KnownNat m, KnownNat (n + m), TensorScalar a) => Tensor '[n] a -> Tensor '[m] a -> Tensor '[n + m] a

-- | Splits a 1-dimensional tensor into 2 parts. Inverse of tconcat. Runs
--   in O(n+m) time.
tsplit :: (KnownNat n, KnownNat m, TensorScalar a) => Tensor '[n + m] a -> (Tensor '[n] a, Tensor '[m] a)

-- | Computes the elementwise maximum of 2 tensors.
elementwiseMax :: (Shape s, TensorScalar a) => Tensor s a -> Tensor s a -> Tensor s a
instance Generic (STensor a)
instance Datatype D1STensor
instance Constructor C1_0STensor
instance (Shape s, TensorScalar a) => InnerSpace (Tensor s a)
instance (Shape s, TensorScalar a) => VectorSpace (Tensor s a)
instance (Shape s, TensorScalar a) => AdditiveGroup (Tensor s a)
instance (Shape s, TensorScalar a) => Floating (Tensor s a)
instance (Shape s, TensorScalar a) => Fractional (Tensor s a)
instance (TensorScalar a, Shape s) => Num (Tensor s a)
instance (Shape s, TensorScalar a, Show a) => Show (Tensor s a)
instance (NFData a, Generic a, TensorScalar a) => NFData (Tensor s a)
instance (Shape s, Serialize a, Generic a, TensorScalar a) => Serialize (Tensor s a)
instance (Shape s, Generic a, TensorScalar a) => Generic (Tensor s a)

module DeepBanana.Data
load_mnist :: Convertible StorageImage i => FilePath -> IO [(i, Int)]
load_mnist_lazy :: (MonadIO m, Convertible StorageImage i) => FilePath -> Producer (i, Int) m ()
lazy_image_loader :: (Image i, Convertible StorageImage i, Storable (ImagePixel i), MonadIO m) => Proxy i -> FilePath -> Pipe (FilePath, [Int]) (Manifest (ImagePixel i), [Int]) m ()
randomize :: (MonadIO m, MonadRandom m) => [a] -> (a -> m b) -> Producer b m ()
map_pixels :: (FunctorImage src dst, Monad m) => (ImagePixel src -> ImagePixel dst) -> Pipe src dst m ()
batch_images :: (Image i, Storable (PixelChannel (ImagePixel i)), Pixel (ImagePixel i), Monad m, TensorScalar a) => Int -> Int -> Pipe (i, [Int]) (Vector (PixelChannel (ImagePixel i)), Vector a) m ()
batch_to_gpu :: (MonadIO m, TensorScalar a, Shape s1, Shape s2) => Proxy '[s1, s2] -> Pipe (Vector a, Vector a) (Tensor s1 a, Tensor s2 a) m ()
runEvery :: Monad m => Int -> (a -> m ()) -> Pipe a a m c
serializeTo :: (MonadIO m, Serialize a) => FilePath -> a -> m ()
random_crop :: (Image i, Storable (ImagePixel i), MonadRandom m) => Proxy i -> Int -> Int -> Pipe (Manifest (ImagePixel i), l) (Manifest (ImagePixel i), l) m ()
instance Storable i => Serialize (Manifest i)

module DeepBanana.Layer.CUDA.CuDNN
convolution2d :: (TensorScalar a, Shape input_shape, Shape filter_shape, Shape padding, Shape stride, Shape out_shape, out_shape ~ ConvOutShape input_shape filter_shape padding stride, Nbdim input_shape ~ 4, Nbdim filter_shape ~ 4, Nbdim out_shape ~ 4, Nbdim stride ~ 2, Nbdim padding ~ 2) => Proxy '[padding, stride] -> ConvolutionFwdAlgo -> Layer CUDA a '[Tensor filter_shape a] (Tensor input_shape a) (Tensor out_shape a)
convolution_fwd_algo_implicit_gemm :: ConvolutionFwdAlgo
convolution_fwd_algo_implicit_precomp_gemm :: ConvolutionFwdAlgo
convolution_fwd_algo_gemm :: ConvolutionFwdAlgo
convolution_fwd_algo_direct :: ConvolutionFwdAlgo
activation :: (TensorScalar a, Shape s, Nbdim s ~ 4) => ActivationMode -> Layer CUDA a [] (Tensor s a) (Tensor s a)
activation_sigmoid :: ActivationMode
activation_relu :: ActivationMode
activation_tanh :: ActivationMode
pooling2d :: (TensorScalar a, Shape input_shape, Shape pooling_size, Shape padding, Shape stride, Shape out_shape, out_shape ~ PoolOutShape input_shape pooling_size padding stride, Nbdim input_shape ~ 4, Nbdim out_shape ~ 4, Nbdim pooling_size ~ 2, Nbdim padding ~ 2, Nbdim stride ~ 2) => Proxy '[pooling_size, padding, stride] -> PoolingMode -> Layer CUDA a [] (Tensor input_shape a) (Tensor out_shape a)
pooling_max :: PoolingMode
pooling_average_count_include_padding :: PoolingMode
pooling_average_count_exclude_padding :: PoolingMode
nhwc_to_nchw :: (TensorScalar a, KnownNat n, KnownNat c, KnownNat h, KnownNat w) => Layer CUDA a [] (Tensor '[n, h, w, c] a) (Tensor '[n, c, h, w] a)
nchw_to_nhwc :: (TensorScalar a, KnownNat n, KnownNat c, KnownNat h, KnownNat w) => Layer CUDA a [] (Tensor '[n, c, h, w] a) (Tensor '[n, h, w, c] a)

module DeepBanana.Layer.CUDA.Cublas
linear :: (TensorScalar a, KnownNat m, KnownNat n, KnownNat k) => Layer CUDA a '[Tensor '[m, k] a] (Tensor '[n, m] a) (Tensor '[n, k] a)
sumCols :: (TensorScalar a, KnownNat n, KnownNat m) => Layer CUDA a [] (Tensor '[n, m] a) (Tensor '[1, m] a)
sumRows :: (TensorScalar a, KnownNat n, KnownNat m) => Layer CUDA a [] (Tensor '[n, m] a) (Tensor '[n, 1] a)
replicateAsRows :: (TensorScalar a, KnownNat n, KnownNat m) => Proxy n -> Layer CUDA a [] (Tensor '[m] a) (Tensor '[n, m] a)
replicateAsCols :: (TensorScalar a, KnownNat n, KnownNat m) => Proxy n -> Layer CUDA a [] (Tensor '[m] a) (Tensor '[m, n] a)

module DeepBanana.Layer.CUDA.CuRAND
dropout :: (TensorScalar a, Shape s) => a -> Layer CUDA a [] (Tensor s a) (Tensor s a)
uniform :: (TensorScalar a, Shape s) => CUDA (Tensor s a)
normal :: (TensorScalar a, Shape s) => a -> a -> CUDA (Tensor s a)
logNormal :: (TensorScalar a, Shape s) => a -> a -> CUDA (Tensor s a)

module DeepBanana.Layer.CUDA.Numeric
llog :: (TensorScalar a, Shape s) => Layer CUDA a [] (Tensor s a) (Tensor s a)
inv :: (TensorScalar a, Shape s) => Layer CUDA a [] (Tensor s a) (Tensor s a)
lexp :: (TensorScalar a, Shape s) => Layer CUDA a [] (Tensor s a) (Tensor s a)
scale :: (TensorScalar a, Shape s) => Layer CUDA a [] (a, Tensor s a) (Tensor s a)
multiply :: (TensorScalar a, Shape s) => Layer CUDA a [] (Tensor s a, Tensor s a) (Tensor s a)
add :: (TensorScalar a, Shape s) => Layer CUDA a [] (Tensor s a, Tensor s a) (Tensor s a)

module DeepBanana.Layer.CUDA
softmax :: (TensorScalar a, KnownNat n, KnownNat m) => Layer CUDA a [] (Tensor '[n, m] a) (Tensor '[n, m] a)
lreshape :: (TensorScalar a, Shape s1, Shape s2, Size s1 ~ Size s2) => Layer CUDA a [] (Tensor s1 a) (Tensor s2 a)
toScalar :: (TensorScalar a, Shape s, Size s ~ 1) => Layer CUDA a [] (Tensor s a) a
mlrCost :: (TensorScalar a, KnownNat n, KnownNat m) => Layer CUDA a [] (Tensor '[n, m] a, Tensor '[n, m] a) a

module DeepBanana
